[
{
	"uri": "//localhost:1313/",
	"title": "AWS S3 Logging",
	"tags": [],
	"description": "",
	"content": "AWS S3 Logging Workshop Overall In this workshop, we will use AWS S3 server access logging and AWS CloudTrail to logging when thereis operation on our S3 objects. Then we will use AWS Athena to query log.\nContent Introduction Preparation S3 Server Access Logging Apply AWS CloudTrail Log query with Athena Clean up "
},
{
	"uri": "//localhost:1313/1-introduce/",
	"title": "Introduction",
	"tags": [],
	"description": "",
	"content": "When you use logging with Amazon S3, you can record actions taken by users, and services on your Amazon S3 resources. You can then use the log records for auditing and compliance purposes.\nYou can log Amazon S3 actions using server access logs or AWS CloudTrail logs.\nServer access logging is a mechanism that provides detailed records for requests made to an S3 bucket.\nServer access logging is disabled by default. Enable server access logging to start receiving logs. Log records are generally delivered within a few hours and it is rare to lose log records. There is no charge for enabling access logging, nor for PUT operations for log files. You are only charged for storage of the logs and for GET operations on the files. You can use object lifecycle management to minimize storage costs.\nAWS CloudTrail is a service that provides records of actions taken by a user, role, or service in your AWS Account. You can use CloudTrail to audit your account by logging and monitoring all activity. You can also use CloudTrail to detect unusual activity in your account.\nLogging Amazon S3 actions with AWS CloudTrail helps keep your account secure by providing access auditing and analysis.\nComparison\nLog properties AWS CloudTrail Amazon S3 server logs Can be forwarded to other systems (Amazon CloudWatch Logs, Amazon CloudWatch Events) Yes No Deliver logs to more than one destination (for example, send the same logs to two different buckets) Yes No Turn on logs for a subset of objects (prefix) Yes No Cross-account log delivery (target and source bucket owned by different accounts) Yes No Integrity validation of log file by using digital signature or hashing Yes No Default or choice of encryption for log files Yes No Object operations (by using Amazon S3 APIs) Yes Yes Bucket operations (by using Amazon S3 APIs) Yes Yes Searchable UI for logs Yes No Fields for Object Lock parameters, Amazon S3 Select properties for log records Yes No Amazon Athena is an interactive query service that makes it easy for you to analyze data in Amazon S3 using standard SQL. You do not need to manage any infrastructure with Athena, and you pay only for the queries that you run.\nOnce you enable server access logs and store them in your target S3 bucket, you might want to analyze or search through them. Logs are not automatically analyzed by Amazon S3, and you might have a lot of data. To analyze all your Amazon S3 data, you can use Amazon Athena.\n"
},
{
	"uri": "//localhost:1313/2-prerequiste/2.5-file/",
	"title": "Access the file ",
	"tags": [],
	"description": "",
	"content": "Access the file In bucket console, select file S3_logging_workshop.txt. Copy Object URL. Access the file in browser. "
},
{
	"uri": "//localhost:1313/2-prerequiste/2.1-2buckets/",
	"title": "Create 2 bucket ",
	"tags": [],
	"description": "",
	"content": "Create 2 bucket At AWS Management Console, find S3 and select S3. At S3 console, select Create bucket. In create bucket steps: For AWS Region, select Asia Pacific (Singapore) ap-southeast-1. For Bucket name, insert logging-workshop. Tiếp tục: For Block Public Access settings for this bucket, untick Block all public access. For Turning off block all public access might result in this bucket and the objects within becoming public, confirm this. Scroll down, select Create bucket. Confirm bucket is created successfully. Continue creating bucket logging-workshop-destination For AWS Region, select Asia Pacific (Singapore) ap-southeast-1. For Bucket name, insert logging-workshop-destination. No need to untick Block Public Access settings for this bucket. Scroll down, select Create bucket. Confirm bucket is created successfully. "
},
{
	"uri": "//localhost:1313/2-prerequiste/2.4-policy/",
	"title": "Edit policy ",
	"tags": [],
	"description": "",
	"content": "Thêm policy cho bucket In S3 console, select logging-workshop bucket. Select Permissions tab. for Bucket policy, select Edit. Insert: { \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Principal\u0026#34;: \u0026#34;*\u0026#34;, \u0026#34;Action\u0026#34;: \u0026#34;s3:GetObject\u0026#34;, \u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:s3:::logging-workshop/*\u0026#34; } ] } Chọn Save changes Confirm updated successfully "
},
{
	"uri": "//localhost:1313/2-prerequiste/",
	"title": "Preparation ",
	"tags": [],
	"description": "",
	"content": "To prepare for this workshop, we will create 1 group with public access to hold the files we need to access and 1 private group to hold the server access logs.\nContent Create 2 bucket Update permissiong Upload file to bucket Add policy for bucket Access files "
},
{
	"uri": "//localhost:1313/2-prerequiste/2.2-permission/",
	"title": "Update logging permission ",
	"tags": [],
	"description": "",
	"content": "Cập nhật quyền tạo log cho S3 log delivery group Return to bucket console, select bucket logging-workshop-destination. Scroll down to section Object Ownership, select Edit Select ACLs enabled, confirm I acknowledge that ACLS will be restored., select Save changes. This will make everythin in the Access control list (ACL) can create object. Scroll down to section Access control list (ACL), select Edit. At S3 log delivery group, select Write, then Save changes. Confrim Write for S3 log delivery group. Return to bucket console. "
},
{
	"uri": "//localhost:1313/2-prerequiste/2.3-upload/",
	"title": "Upload file to S3 bucket ",
	"tags": [],
	"description": "",
	"content": "Upload file vào bucket Select bucket logging-workshop. Then, select Upload. Select Add files. Then: Download S3_logging_workshop.txt here Attachments\rS3_logging_workshop.txt\r(0 ko)\rOpen in a new tab, Ctrl + S to save the file to your local.\nconfirm the file is selected Select Upload. Confirm uploaded successfully. "
},
{
	"uri": "//localhost:1313/3-s3sal/3.2-log/",
	"title": "Check logs",
	"tags": [],
	"description": "",
	"content": "Truy cập file và kiễm tra log Open new private tab and acces the file.\nIn buckets console, select bucket logging-workshop-destination, wait about 15 minutes, refresh the bucket.\nWe can see there are logs there, select one. Select Download and open it. the log file will looks like below: b07c1e6c73fc3be646182d0400a50638e0703b6352275b2d165aa35f9791c572 logging-workshop [03/Mar/2024:12:52:26 +0000] 118.69.159.186 arn:aws:iam::928738046450:user/hung 2ET0N53Y32R632Q5 REST.GET.OWNERSHIP_CONTROLS - \u0026#34;GET /logging-workshop?ownershipControls= HTTP/1.1\u0026#34; 200 - 193 - 53 53 \u0026#34;-\u0026#34; \u0026#34;S3Console/0.4, aws-internal/3 aws-sdk-java/1.12.488 Linux/5.10.209-175.858.amzn2int.x86_64 OpenJDK_64-Bit_Server_VM/25.372-b08 java/1.8.0_372 vendor/Oracle_Corporation cfg/retry-mode/standard\u0026#34; - xqa7XzBU4q1xnx4NmkVBFhDsnt0jk07Slo9F3j2kvD0/6zSveFBzQ5t+Zrfs/me6L4epr6/dG3k= SigV4 ECDHE-RSA-AES128-GCM-SHA256 AuthHeader s3.ap-southeast-1.amazonaws.com TLSv1.2 - -\rb07c1e6c73fc3be646182d0400a50638e0703b6352275b2d165aa35f9791c572 logging-workshop [03/Mar/2024:12:52:28 +0000] 118.69.159.186 arn:aws:iam::928738046450:user/hung YP9K97RHY7C5JPBC REST.GET.OBJECT_TAGGING S3_logging_workshop.txt \u0026#34;GET /logging-workshop/S3_logging_workshop.txt?tagging= HTTP/1.1\u0026#34; 200 - 115 - 13 10 \u0026#34;-\u0026#34; \u0026#34;S3Console/0.4, aws-internal/3 aws-sdk-java/1.12.488 Linux/5.10.209-175.858.amzn2int.x86_64 OpenJDK_64-Bit_Server_VM/25.372-b08 java/1.8.0_372 vendor/Oracle_Corporation cfg/retry-mode/standard\u0026#34; - nGxxv80fXE5xGWiS6C7OIg7/ncxoVho61Lmw9+qyveqdOBbiqRD4HJZf8qU90j0IeUXNGmwcSwA= SigV4 ECDHE-RSA-AES128-GCM-SHA256 AuthHeader s3.ap-southeast-1.amazonaws.com TLSv1.2 - - "
},
{
	"uri": "//localhost:1313/3-s3sal/",
	"title": "Connect to EC2 servers",
	"tags": [],
	"description": "",
	"content": "In this step, we will enable Server access logging.\nContent Enable S3 Server Access Logging Check log "
},
{
	"uri": "//localhost:1313/3-s3sal/3.1-sal/",
	"title": "Enable S3 Server access logging",
	"tags": [],
	"description": "",
	"content": "In this step, we will enable Server access logging.\nServer access logs give you visibility into detailed object-level operations on your data. The log files are text files that have one line for each log record. Each log record represents one request and consists of space-delimited fields.\nThe fields relate to operation, requester, resource, and session information. Here is an example:\n79a59df900b949e55d96a1e698fbacedfd6e09d98eacf8f8d5218e7cd47ef2be awsexamplebucket1 [06/Feb/2019:00:00:38 +0000] 192.0.2.3 79a59df900b949e55d96a1e698fbacedfd6e09d98eacf8f8d5218e7cd47ef2be 3E57427F3EXAMPLE REST.GET.VERSIONING - \u0026#34;GET /awsexamplebucket1?versioning HTTP/1.1\u0026#34; 200 - 113 - 7 - \u0026#34;-\u0026#34; \u0026#34;S3Console/0.4\u0026#34; - s9lzHYrFp76ZVxRcpX9+5cjAnEH2ROuNkd2BHfIa6UkFVdtjf5mKR3/eTPFvsiP/XV/VLi31234= SigV2 ECDHE-RSA-AES128-GCM-SHA256 AuthHeader awsexamplebucket1.s3.us-west-1.amazonaws.com TLSV1.1 Kích hoạt Server access logging In S3 console, select bucket logging-workshop. In bucket console, select Properties. Scroll dowm to Server access logging, select Edit Select Enable, then select Brow S3 for storing the logs afterward. Select bucket logging-workshop-destination, then select Choose destination. Review bucket, then select Save changes. Confirm Server access logging is enabled. "
},
{
	"uri": "//localhost:1313/4-s3cloudtrail/",
	"title": "Logging with AWS CloudTrail",
	"tags": [],
	"description": "",
	"content": " CloudTrail includes 3 main components: Event là record về một hoạt động trong tài khoản AWS. Trail cho phép CloudTrail phân phối log tới bucket Amazon S3, CloudWatch log và CloudWatch event. Log bucket dùng để lưu trữ các file log. Kích hoạt Server access logging Trong giao diện AWS Console, tìm và chọn Cloudtrail. Chọn Create trail Thực hiện: Mục Trail name, nhập S3_logging_workshop. Mục Trail log bucket and folder, nhập aws-cloud-trail-logs-workshop. Mục Log file SSE-KMS encryption, bỏ tick Enable. Kéo xuống dưới và chọn Next. Tại mục Event type, tick chọn thêm Data events. Kéo xuống dưới, tại mục Data events, chọn S3. Sau đó nhấn Next. Review lại và ấn Create trail. Kiểm tra trail đã được tạo thành công. Quay trở về giao diện S3 console, chúng ta có thể thấy bucket aws-cloud-trail-logs-workshop đã được tạo ra để lưu log. Mở một tab ẩn danh mới và nhập URL truy cập tới file chúng ta đã lưu.\nChờ khoảng 10 phút, sau đó refresh. Truy cập vào các folder bên trong cho tới khi chúng ta có thể thấy các file log đã được tạo ra.\nChọn vào 1 file log bất kỳ, ấn Download. Khi xem file log đã được tải về, ta có thể thấy nội dung có dạng JSON như sau: { \u0026#34;Records\u0026#34;: [ { \u0026#34;eventVersion\u0026#34;: \u0026#34;1.09\u0026#34;, \u0026#34;userIdentity\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;IAMUser\u0026#34;, \u0026#34;principalId\u0026#34;: \u0026#34;******\u0026#34;, \u0026#34;arn\u0026#34;: \u0026#34;arn:aws:iam::****:user/****\u0026#34;, \u0026#34;accountId\u0026#34;: \u0026#34;*****\u0026#34;, \u0026#34;accessKeyId\u0026#34;: \u0026#34;*****\u0026#34;, \u0026#34;userName\u0026#34;: \u0026#34;****\u0026#34;, \u0026#34;sessionContext\u0026#34;: { \u0026#34;attributes\u0026#34;: { \u0026#34;creationDate\u0026#34;: \u0026#34;2024-03-03T05:32:58Z\u0026#34;, \u0026#34;mfaAuthenticated\u0026#34;: \u0026#34;false\u0026#34; } } }, \u0026#34;eventTime\u0026#34;: \u0026#34;2024-03-03T14:00:32Z\u0026#34;, \u0026#34;eventSource\u0026#34;: \u0026#34;s3.amazonaws.com\u0026#34;, \u0026#34;eventName\u0026#34;: \u0026#34;GetObject\u0026#34;, \u0026#34;awsRegion\u0026#34;: \u0026#34;ap-southeast-1\u0026#34;, \u0026#34;sourceIPAddress\u0026#34;: \u0026#34;118.69.159.186\u0026#34;, \u0026#34;userAgent\u0026#34;: \u0026#34;[Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/122.0.0.0 Safari/537.36 Edg/122.0.0.0]\u0026#34;, \u0026#34;requestParameters\u0026#34;: { \u0026#34;X-Amz-Date\u0026#34;: \u0026#34;20240303T140026Z\u0026#34;, \u0026#34;bucketName\u0026#34;: \u0026#34;aws-cloudtrail-logs-workshop\u0026#34;, \u0026#34;X-Amz-Algorithm\u0026#34;: \u0026#34;AWS4-HMAC-SHA256\u0026#34;, \u0026#34;response-content-disposition\u0026#34;: \u0026#34;attachment\u0026#34;, \u0026#34;X-Amz-SignedHeaders\u0026#34;: \u0026#34;host\u0026#34;, \u0026#34;Host\u0026#34;: \u0026#34;aws-cloudtrail-logs-workshop.s3.ap-southeast-1.amazonaws.com\u0026#34;, \u0026#34;X-Amz-Expires\u0026#34;: \u0026#34;300\u0026#34;, \u0026#34;key\u0026#34;: \u0026#34;AWSLogs/*****/CloudTrail/ap-southeast-1/2024/03/03/*****_CloudTrail_ap-southeast-1_20240303T1355Z_FXZWnsQMI7Esmlr6.json.gz\u0026#34; }, \u0026#34;responseElements\u0026#34;: null, \u0026#34;additionalEventData\u0026#34;: { \u0026#34;SignatureVersion\u0026#34;: \u0026#34;SigV4\u0026#34;, \u0026#34;CipherSuite\u0026#34;: \u0026#34;ECDHE-RSA-AES128-GCM-SHA256\u0026#34;, \u0026#34;bytesTransferredIn\u0026#34;: 0, \u0026#34;AuthenticationMethod\u0026#34;: \u0026#34;QueryString\u0026#34;, \u0026#34;x-amz-id-2\u0026#34;: \u0026#34;0nSxx7oCCBTlrpXwQsLYoA0MqHo/+k/FiMnikrVCDKiWDr1Aoeg7oSqlJvBsYm2J3BnFpU31IUA=\u0026#34;, \u0026#34;bytesTransferredOut\u0026#34;: 7759 }, \u0026#34;requestID\u0026#34;: \u0026#34;MB8NVKR3FVMSSRM9\u0026#34;, \u0026#34;eventID\u0026#34;: \u0026#34;3d4906c8-52ce-456f-bc0a-a89f07b364a0\u0026#34;, \u0026#34;readOnly\u0026#34;: true, \u0026#34;resources\u0026#34;: [ { \u0026#34;type\u0026#34;: \u0026#34;AWS::S3::Object\u0026#34;, \u0026#34;ARN\u0026#34;: \u0026#34;arn:aws:s3:::aws-cloudtrail-logs-workshop/AWSLogs/*****/CloudTrail/ap-southeast-1/2024/03/03/*****_CloudTrail_ap-southeast-1_20240303T1355Z_FXZWnsQMI7Esmlr6.json.gz\u0026#34; }, { \u0026#34;accountId\u0026#34;: \u0026#34;*****\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;AWS::S3::Bucket\u0026#34;, \u0026#34;ARN\u0026#34;: \u0026#34;arn:aws:s3:::aws-cloudtrail-logs-workshop\u0026#34; } ], \u0026#34;eventType\u0026#34;: \u0026#34;AwsApiCall\u0026#34;, \u0026#34;managementEvent\u0026#34;: false, \u0026#34;recipientAccountId\u0026#34;: \u0026#34;*****\u0026#34;, \u0026#34;eventCategory\u0026#34;: \u0026#34;Data\u0026#34;, \u0026#34;tlsDetails\u0026#34;: { \u0026#34;tlsVersion\u0026#34;: \u0026#34;TLSv1.2\u0026#34;, \u0026#34;cipherSuite\u0026#34;: \u0026#34;ECDHE-RSA-AES128-GCM-SHA256\u0026#34;, \u0026#34;clientProvidedHostHeader\u0026#34;: \u0026#34;aws-cloudtrail-logs-workshop.s3.ap-southeast-1.amazonaws.com\u0026#34; } } ] } "
},
{
	"uri": "//localhost:1313/5-s3athena/",
	"title": "Port Forwarding",
	"tags": [],
	"description": "",
	"content": "Sử dụng Athena với CloudTrail log là một cách để nâng cao khả năng phân tích của bạn về hoạt động dịch vụ AWS. Ví dụ: bạn có thể sử dụng truy vấn để xác định xu hướng và tách biệt hơn nữa hoạt động theo thuộc tính, chẳng hạn như địa chỉ IP nguồn hoặc người dùng.\nTruy cập vào CloudTrail console. Ở bảng điều hướng bên trái, chọn Event history. Sau đó chọn Create Athena table. Tại muc Storage location, chọn bucket aws-cloud-trail-logs-workshop mà ta đang dùng để lưu trữ CloudTrail log. Sau đó chọn Create table. Xác nhận Athena table cloudtrail_logs_aws_cloudtrail_logs_workshop đã được tạo. Tìm và chọn service Athena, sau đó chọn Launch query editor. Nếu như đây là lần đầu bạn sử dụng Athena thì ấn Edit settings, nếu không thì bạn có thể tiếp tục tại bước số 10. Ấn Browse S3. Chọn 1 bucket để lưu kết quả khi query, ở đây chúng ta sử dụng bucket logging-workshop-destination. Kiểm tra và ấn Save. Kiểm tra và ấn Editor để quay trở về. Copy đoạn code dưới đây vào editor, hãy đảm bảo tên table mà ta đang query giống với tên table ở bảng bên trái. Query này sẽ lọc ra những log hành động GetObject có eventsource là s3.amazonaws.com. Sau đó ấn Run. SELECT * FROM cloudtrail_logs_aws_cloudtrail_logs_workshop WHERE eventsource = \u0026#39;s3.amazonaws.com\u0026#39; AND eventname in (\u0026#39;GetObject\u0026#39;) Kiểm tra kết quả query ở ngay bên dưới. Sau khi thành công, hãy chạy đoạn query sau trong editor để xóa table DROP TABLE `cloudtrail_logs_aws_cloudtrail_logs_workshop` "
},
{
	"uri": "//localhost:1313/6-cleanup/",
	"title": "Clean up",
	"tags": [],
	"description": "",
	"content": "We will take the following steps to delete the resources we created in this exercise.\nDelete EC2 instance Go to EC2 service management console\nClick Instances. Select both Public Linux Instance and Private Windows Instance instances. Click Instance state. Click Terminate instance, then click Terminate to confirm. Go to IAM service management console\nClick Roles. In the search box, enter SSM. Click to select SSM-Role. Click Delete, then enter the role name SSM-Role and click Delete to delete the role. Click Users. Click on user Portfwd. Click Delete, then enter the user name Portfwd and click Delete to delete the user. Delete S3 bucket Access System Manager - Session Manager service management console.\nClick the Preferences tab. Click Edit. Scroll down. In the section S3 logging. Uncheck Enable to disable logging. Scroll down. Click Save. Go to S3 service management console\nClick on the S3 bucket we created for this lab. (Example: lab-fcj-bucket-0001 ) Click Empty. Enter permanently delete, then click Empty to proceed to delete the object in the bucket. Click Exit. After deleting all objects in the bucket, click Delete\nEnter the name of the S3 bucket, then click Delete bucket to proceed with deleting the S3 bucket. Delete VPC Endpoints Go to VPC service management console Click Endpoints. Select the 4 endpoints we created for the lab including SSM, SSMMESSAGES, EC2MESSAGES, S3GW. Click Actions. Click Delete VPC endpoints. In the confirm box, enter delete.\nClick Delete to proceed with deleting endpoints. Click the refresh icon, check that all endpoints have been deleted before proceeding to the next step.\nDelete VPC Go to VPC service management console\nClick Your VPCs. Click on Lab VPC. Click Actions. Click Delete VPC. In the confirm box, enter delete to confirm, click Delete to delete Lab VPC and related resources.\n"
},
{
	"uri": "//localhost:1313/categories/",
	"title": "Categories",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "//localhost:1313/tags/",
	"title": "Tags",
	"tags": [],
	"description": "",
	"content": ""
}]